{"cells":[{"cell_type":"code","source":["# version with filter for two tables + caching\n","\n","from pyspark.sql.functions import to_date, col\n","\n","ctrl = spark.table(\"cdf_control_silver_part\").filter(\"table_name = 'tbl_bronze'\").first()\n","last_version = ctrl[\"last_version\"]     #946\n","\n","\n","\n","# find current table version\n","current_version = spark.sql(\"DESCRIBE HISTORY tbl_bronze\")\\\n","                       .selectExpr(\"max(version) as v\")\\\n","                       .first()[\"v\"]\n","\n","if current_version > last_version:\n","\n","    # get changes and add partition_date column\n","    changes_df = spark.sql(f\"\"\"\n","    SELECT \n","            timestamp,\n","            symbol,\n","            exchange,\n","            event_type,\n","            latency_ms,\n","            order_id,\n","            transaction_type,\n","            price,\n","            volume,\n","            bid_price,\n","            ask_price,\n","            bid_size,\n","            ask_size,\n","            canceled_order_id,\n","            currency,\n","            trade_id,\n","            event_id,\n","            EventProcessedUtcTime,\n","            PartitionId,\n","            EventEnqueuedUtcTime   \n","    FROM table_changes('tbl_bronze', {last_version})\n","    WHERE _change_type = 'insert'\n","    \"\"\")\n","\n","    with_date = changes_df \\\n","    .withColumn(\"partition_date\", to_date(col(\"timestamp\"))) \\\n","    .cache()                   #  cacheujemy wynik\n","\n","    # filter once per cached object\n","    usd_df = with_date.filter(col(\"currency\") == \"USD\")\n","    wrong_df = with_date.filter(col(\"currency\") != \"USD\")\n","\n","    # save both together, but without recalculating\n","    usd_df.write \\\n","        .format(\"delta\") \\\n","        .mode(\"append\") \\\n","        .saveAsTable(\"tbl_silver_part\")\n","\n","    wrong_df.write \\\n","        .format(\"delta\") \\\n","        .mode(\"append\") \\\n","        .saveAsTable(\"tbl_silver_wrong_currency\")\n","\n","    # refresh the control table\n","    spark.sql(f\"\"\"\n","    UPDATE cdf_control_silver_part\n","    SET last_version = {current_version}\n","    WHERE table_name = 'tbl_bronze'\n","    \"\"\")\n","\n","else:\n","    print(\"Brak nowych zmian do przetworzenia.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"2f7629e2-8f8a-4935-8cce-3c344bb56654","normalized_state":"finished","queued_time":"2025-07-27T12:24:08.3861214Z","session_start_time":null,"execution_start_time":"2025-07-27T12:24:08.387304Z","execution_finish_time":"2025-07-27T12:24:23.1887653Z","parent_msg_id":"95704638-4db8-41ac-bb27-f6eb745725ce"},"text/plain":"StatementMeta(, 2f7629e2-8f8a-4935-8cce-3c344bb56654, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"editable":true,"run_control":{"frozen":false}},"id":"2640adf8-e677-43bc-8bc2-5ba6e39cada7"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"3e9dce0a-276e-4aff-89b5-8421ada22841"}],"default_lakehouse":"3e9dce0a-276e-4aff-89b5-8421ada22841","default_lakehouse_name":"lh_stockanaliser","default_lakehouse_workspace_id":"bd023394-0e77-42e1-8a25-8a9cbc7a7377"}}},"nbformat":4,"nbformat_minor":5}